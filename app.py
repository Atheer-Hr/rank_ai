import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.linear_model import LinearRegression

# ======================================================================
# ğŸ› ï¸ 1. Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ (Smart Import)
# ======================================================================
try:
    import tensorflow as tf
    Interpreter = tf.lite.Interpreter
except ImportError:
    try:
        from tensorflow.lite import Interpreter
    except ImportError:
        try:
            from tflite_runtime.interpreter import Interpreter
        except ImportError:
            st.error("âŒ Ø®Ø·Ø£: Ù…ÙƒØªØ¨Ø© TensorFlow ØºÙŠØ± Ù…Ø«Ø¨ØªØ© (ØªØ£ÙƒØ¯ Ù…Ù† requirements.txt).")
            st.stop()

# ======================================================================
# -------------------- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ØµÙˆÙ„ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª --------------------
# ======================================================================

@st.cache_resource
def load_assets_lite():
    # Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„Ø«Ø§Ø¨ØªØ©
    recommendations_map = {
        "Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù„Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ø´Ø±ÙŠ": "ØªØ·ÙˆÙŠØ± Ø¨Ø±Ø§Ù…Ø¬ ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ù…Ø³ØªÙ…Ø±Ø© Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙØ±Ø¯ÙŠ.",
        "Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬": "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù…Ù†Ø§Ù‡Ø¬ ÙˆØªØ­Ø¯ÙŠØ«Ù‡Ø§ Ù„ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø±Ù† 21.",
        "Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ": "Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù‡Ù†ÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ù…Ø¹ Ø­ÙˆØ§ÙØ² Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ø§Ø².",
        "ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø´Ø®ØµÙŠØ©": "Ø¥Ø·Ù„Ø§Ù‚ Ø¨Ø±Ø§Ù…Ø¬ Ø¥Ø±Ø´Ø§Ø¯ Ù†ÙØ³ÙŠ ÙˆØ§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ù‚ÙŠØ§Ø¯Ø© Ù„Ø¯Ù‰ Ø§Ù„Ø·Ù„Ø§Ø¨.",
        "Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªØ±Ø¨ÙˆÙŠ": "ØªØ·ÙˆÙŠØ± Ø£Ø¯ÙˆØ§Øª ØªÙ‚ÙŠÙŠÙ… Ù…Ø¹ÙŠØ§Ø±ÙŠØ© Ø±Ù‚Ù…ÙŠØ© Ù„Ù‚ÙŠØ§Ø³ Ù†ÙˆØ§ØªØ¬ Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø¯Ù‚Ø©.",
        "Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø§Øµ": "ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§ÙƒØ§Øª Ù…Ø¹ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ù„Ø¯Ø¹Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù…Ù„ÙŠ ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„ØªÙ‚Ù†ÙŠØ©.",
        "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø³Ø±Ø©": "ØªÙØ¹ÙŠÙ„ Ù…Ø¬Ø§Ù„Ø³ Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ¥Ø´Ø±Ø§ÙƒÙ‡Ù… ÙÙŠ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ.",
        "Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ù…Ø¨Ø§Ù†ÙŠ": "ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© ÙˆØªÙˆÙÙŠØ± Ø¨ÙŠØ¦Ø© ØµÙÙŠØ© Ø¬Ø§Ø°Ø¨Ø© ÙˆØ¢Ù…Ù†Ø©.",
        "Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³": "ØªØ¹Ù…ÙŠÙ… Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ù…Ù†ØµØ§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø±Ù‚Ù…ÙŠØ©.",
        "Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ": "Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs) Ù„Ù…ØªØ§Ø¨Ø¹Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ.",
        "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ³": "ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªØ¹Ù„Ù… Ù†Ø´Ø· ÙˆØªØ¯Ø±ÙŠØ³ ØªÙØ±ÙŠØ¯ÙŠØ© ØªØ±Ø§Ø¹ÙŠ Ø§Ù„ÙØ±ÙˆÙ‚ Ø§Ù„ÙØ±Ø¯ÙŠØ©.",
        "Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©": "Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø¹ÙŠØ§Ø±ÙŠØ© ÙˆØ·Ù†ÙŠØ© Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ ÙˆØ§Ù„Ù…Ù†Ø§Ø·Ù‚."
    }
    
    execution_plan_map = {
        "Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù„Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ø´Ø±ÙŠ": "ØªÙˆØ²ÙŠØ¹ Ø¨Ø±Ø§Ù…Ø¬ ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø­Ø³Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ù†ÙˆÙŠ.",
        "Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬": "ØªØ´ÙƒÙŠÙ„ Ù„Ø¬Ø§Ù† Ù…Ø±Ø§Ø¬Ø¹Ø© Ù„Ù„Ù…Ù†Ø§Ù‡Ø¬ ÙˆØ±Ø¨Ø· Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©.",
        "Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ": "ØªØµÙ…ÙŠÙ… Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù‡Ù†ÙŠØ© ÙØ±Ø¯ÙŠØ© Ù…Ø¹ Ù…ØªØ§Ø¨Ø¹Ø© ÙØµÙ„ÙŠØ© ÙˆØªÙ‚ÙŠÙŠÙ… ØªØ·Ø¨ÙŠÙ‚ÙŠ.",
        "ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø´Ø®ØµÙŠØ©": "ØªÙ†ÙÙŠØ° Ø£Ù†Ø´Ø·Ø© ØµÙÙŠØ© ÙˆÙ„Ø§ØµÙÙŠØ© ØªØ¹Ø²Ø² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙˆØ§Ù„Ø§Ù†Ø¶Ø¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ.",
        "Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªØ±Ø¨ÙˆÙŠ": "Ø¥Ø¹Ø§Ø¯Ø© ØªØµÙ…ÙŠÙ… Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙ‚ÙˆÙŠÙ… ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ.",
        "Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø§Øµ": "ØªÙˆÙ‚ÙŠØ¹ Ø§ØªÙØ§Ù‚ÙŠØ§Øª ØªØ¹Ø§ÙˆÙ† Ù…Ø¹ Ø´Ø±ÙƒØ§Øª Ù…Ø­Ù„ÙŠØ© Ù„Ø¯Ø¹Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ù…Ø±Ø§ÙÙ‚.",
        "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø³Ø±Ø©": "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØµØ© ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡.",
        "Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ù…Ø¨Ø§Ù†ÙŠ": "ØªØ­Ø¯ÙŠØ¯ Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„ØµÙŠØ§Ù†Ø© ÙˆØ§Ù„ØªØ¬Ù‡ÙŠØ² Ø­Ø³Ø¨ ÙƒØ«Ø§ÙØ© Ø§Ù„Ø·Ù„Ø§Ø¨.",
        "Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³": "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ù…Ù†ØµØ§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ø¹Ù„ÙŠÙ‡Ø§.",
        "Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ": "ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø§Ù… Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ Ø´Ù‡Ø±ÙŠ ÙˆØ±Ø¨Ø·Ù‡ Ø¨Ø§Ù„ØªØ­ÙÙŠØ² Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠ.",
        "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ³": "ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø· ÙˆØ§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªÙƒÙˆÙŠÙ†ÙŠ.",
        "Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©": "ØªØµÙ…ÙŠÙ… Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ·Ù†ÙŠØ© Ù…ÙˆØ­Ø¯Ø© ÙˆØ±Ø¨Ø· Ù†ØªØ§Ø¦Ø¬Ù‡Ø§ Ø¨Ø®Ø·Ø· Ø§Ù„ØªØ­Ø³ÙŠÙ†."
    }
    
    clusters = {
        "ØªØ¹Ù„ÙŠÙ…": {"Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ³","Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬","Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ"},
        "ØªÙ‚ÙŠÙŠÙ…": {"Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªØ±Ø¨ÙˆÙŠ","Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©","Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ"},
        "Ø£Ø³Ø±Ø© ÙˆÙ…Ø¬ØªÙ…Ø¹": {"Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø³Ø±Ø©","Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø§Øµ","ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø´Ø®ØµÙŠØ©"},
        "Ø¨ÙŠØ¦Ø© ÙˆØªØ¬Ù‡ÙŠØ²": {"Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ù…Ø¨Ø§Ù†ÙŠ","Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³"}
    }

    try:
        if not os.path.exists('ranking_model_lite.tflite'): return None
        interpreter = Interpreter(model_path='ranking_model_lite.tflite')
        interpreter.allocate_tensors()

        scaler_X = joblib.load('scaler_X_lite.pkl')
        scaler_y = joblib.load('scaler_y_lite.pkl')
        
        indicator_names = []
        if os.path.exists('indicator_names_lite.txt'):
            with open('indicator_names_lite.txt', 'r', encoding='utf-8') as f:
                indicator_names = [line.strip() for line in f]
        
        feature_importance_map = joblib.load('feature_importance_map.pkl') if os.path.exists('feature_importance_map.pkl') else {}
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ù„Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø¨Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙØ§Ø±ØºØ©
        if not feature_importance_map and indicator_names:
            feature_importance_map = {name: 1.0 for name in indicator_names}

        return interpreter, scaler_X, scaler_y, indicator_names, recommendations_map, execution_plan_map, clusters, feature_importance_map
    
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ØµÙˆÙ„: {e}")
        return None

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ØµÙˆÙ„
loaded_assets = load_assets_lite()
if loaded_assets is None:
    st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (.tflite, .pkl, .txt) Ø¨Ø¬Ø§Ù†Ø¨ Ù…Ù„Ù Ø§Ù„ÙƒÙˆØ¯.")
    st.stop()

interpreter, scaler_X, scaler_y, indicator_names, recommendations_map, execution_plan_map, clusters, feature_importance_map = loaded_assets

# ======================================================================
# -------------------- 3. Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ (Forecasting) --------------------
# ======================================================================

def forecast_future_values(df_history, target_years, indicators):
    """
    ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø¨Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
    Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ (Linear Regression) Ù„ÙƒÙ„ Ù…Ø¤Ø´Ø± Ø¹Ù„Ù‰ Ø­Ø¯Ø©.
    """
    future_data = []
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø³Ù†Ø©
    if 'Ø§Ù„Ø³Ù†Ø©' not in df_history.columns:
        st.error("ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø¨Ø§Ø³Ù… 'Ø§Ù„Ø³Ù†Ø©'")
        return None

    years_train = df_history['Ø§Ù„Ø³Ù†Ø©'].values.reshape(-1, 1)

    for future_year in target_years:
        row = {'Ø§Ù„Ø³Ù†Ø©': future_year, 'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': 'Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§'}
        
        for col in indicators:
            if col in df_history.columns:
                # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø®Ø·ÙŠ Ø¨Ø³ÙŠØ· Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Trend)
                model = LinearRegression()
                y_train = df_history[col].values
                model.fit(years_train, y_train)
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©
                predicted_val = model.predict([[future_year]])[0]
                # Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù†Ø·Ù‚ÙŠØ© (Ø¨ÙŠÙ† 0 Ùˆ 100)
                predicted_val = max(0.0, min(100.0, predicted_val))
                
                row[col] = predicted_val
            else:
                row[col] = 0.0 # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø­Ø§Ù„ Ù†Ù‚Øµ Ø§Ù„Ø¹Ù…ÙˆØ¯
        
        future_data.append(row)
    
    return pd.DataFrame(future_data)

# ======================================================================
# -------------------- 4. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ranking AI) --------------------
# ======================================================================

def run_ai_ranking(input_values, interpreter, scaler_X, scaler_y, indicator_names):
    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    input_array = np.array([input_values]).astype(np.float32)
    X_scaled = scaler_X.transform(input_array)
    
    # TFLite Inference
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    interpreter.set_tensor(input_details[0]['index'], X_scaled)
    interpreter.invoke()
    y_scaled = interpreter.get_tensor(output_details[0]['index'])
    
    # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ø§Ù„ØªØ±ØªÙŠØ¨)
    rank = scaler_y.inverse_transform(y_scaled).flatten()[0]
    return rank

def analyze_year(row_data, indicator_names):
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ… ÙÙ‚Ø· Ù„Ù„ØªØ­Ù„ÙŠÙ„
    values = [row_data[col] for col in indicator_names]
    
    # 1. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
    rank_pred = run_ai_ranking(values, interpreter, scaler_X, scaler_y, indicator_names)
    
    # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¶Ø¹ÙŠÙØ©
    # (Ù†Ù‚ÙˆÙ… Ø¨ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù„ÙŠØ§Ù‹ Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø¶Ø¹Ù Ù†Ø³Ø¨ÙŠØ§Ù‹)
    scaled_vals = np.array(values) / 100.0 
    risks = sorted(zip(indicator_names, scaled_vals), key=lambda x: x[1])
    top_weak_inds = [r[0] for r in risks[:5]]
    
    # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¢Ø²Ø± ÙˆØ§Ù„Ù…ÙƒØ§Ø³Ø¨
    m_synergy = 0
    selected_set = set(top_weak_inds)
    hits = {c: len(selected_set & members) for c, members in clusters.items()}
    same_cluster_boost = sum(1 for _, v in hits.items() if v >= 2) * 0.08
    multi_cluster_boost = sum(1 for _, v in hits.items() if v >= 1) * 0.03
    m_synergy = min(1.0 + same_cluster_boost + multi_cluster_boost, 1.25)
    
    importance_sum = sum([feature_importance_map.get(i, 0.05) for i in top_weak_inds])
    total_gain = rank_pred * 0.1 * importance_sum * m_synergy
    
    return rank_pred, total_gain, m_synergy, top_weak_inds

# ======================================================================
# -------------------- 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Streamlit UI) --------------------
# ======================================================================

st.set_page_config(layout="wide", page_title="Ù…Ù†ØµØ© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ")

# ØªÙ†Ø³ÙŠÙ‚ Ø¹Ø±Ø¨ÙŠ
st.markdown("""
    <style>
        .main { direction: rtl; }
        div[data-testid="stFileUploader"] { text-align: right; }
        h1, h2, h3, p, div { text-align: right; }
        .stDataFrame { direction: rtl; }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸš€ Ù…Ù†ØµØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³")
st.markdown("### Ù†Ø¸Ø§Ù… ØªÙ†Ø¨Ø¤ÙŠ Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (Data-Driven Forecasting)")
st.markdown("---")

# --- Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ: Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³Ù†ÙˆØ§Øª ---
st.sidebar.header("ğŸ“‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")

uploaded_file = st.sidebar.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel (ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©)", type=["xlsx"])

if uploaded_file is not None:
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
    df_history = pd.read_excel(uploaded_file)
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    missing_cols = [col for col in indicator_names if col not in df_history.columns]
    if 'Ø§Ù„Ø³Ù†Ø©' not in df_history.columns:
        st.error("âŒ Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ø³Ù†Ø©'.")
        st.stop()
        
    if missing_cols:
        st.warning(f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù: {missing_cols}. Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø± Ù‚ÙŠÙ…Ù‡Ø§ 0.")

    st.sidebar.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª {len(df_history)} Ø³Ù†ÙˆØ§Øª Ø³Ø§Ø¨Ù‚Ø©.")

    # Ø§Ø®ØªÙŠØ§Ø± Ø³Ù†ÙˆØ§Øª Ø§Ù„ØªÙ†Ø¨Ø¤
    last_year = int(df_history['Ø§Ù„Ø³Ù†Ø©'].max())
    future_years_options = [last_year + i for i in range(1, 6)] # Ø§Ù‚ØªØ±Ø­ 5 Ø³Ù†ÙˆØ§Øª Ù‚Ø§Ø¯Ù…Ø©
    selected_years = st.sidebar.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡Ø§:", future_years_options, default=[last_year+1])
    
    if st.sidebar.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ âš¡", type="primary"):
        
        # 1. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (Forecasting)
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±ØªÙŠØ¨...'):
            df_forecast = forecast_future_values(df_history, selected_years, indicator_names)
            
            if df_forecast is not None:
                st.subheader(f"ğŸ“… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ© Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© ({', '.join(map(str, selected_years))})")
                
                # Ø¹Ù„Ø§Ù…Ø§Øª ØªØ¨ÙˆÙŠØ¨ Ù„Ù„Ø³Ù†ÙˆØ§Øª
                tabs = st.tabs([str(y) for y in selected_years])
                
                for i, year in enumerate(selected_years):
                    with tabs[i]:
                        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„ØªÙ†Ø¨Ø¤
                        current_row = df_forecast[df_forecast['Ø§Ù„Ø³Ù†Ø©'] == year].iloc[0]
                        
                        # ØªØ´ØºÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù†Ø©
                        rank, gain, synergy, weak_inds = analyze_year(current_row, indicator_names)
                        
                        # --- Ø¹Ø±Ø¶ Ù„ÙˆØ­Ø© Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© (Dashboard) ---
                        c1, c2, c3 = st.columns(3)
                        c1.metric("Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡", f"{rank:.2f}")
                        c2.metric("Ù…ÙƒØ³Ø¨ Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹", f"+{gain:.2f}", f"ØªØ¢Ø²Ø±: {synergy:.2f}x")
                        c3.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø©", f"{len(weak_inds)} Ù…Ø¤Ø´Ø±Ø§Øª")
                        
                        st.markdown("#### ğŸ“‰ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù†Ø©")
                        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙƒÙ€ Progress Bars
                        col_ind1, col_ind2 = st.columns(2)
                        for idx, name in enumerate(indicator_names):
                            val = current_row[name]
                            with (col_ind1 if idx % 2 == 0 else col_ind2):
                                st.write(f"**{name}**: {val:.1f}")
                                st.progress(int(val))

                        st.markdown("---")
                        st.markdown("#### ğŸ“ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ®Ø·Ø· Ø§Ù„Ø¹Ù…Ù„")
                        
                        recs_data = []
                        for ind in weak_inds:
                            recs_data.append({
                                "Ø§Ù„Ù…Ø¤Ø´Ø±": ind,
                                "Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ©": f"{feature_importance_map.get(ind, 0):.2f}",
                                "Ø§Ù„ØªÙˆØµÙŠØ©": recommendations_map.get(ind, "-"),
                                "Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ°": execution_plan_map.get(ind, "-")
                            })
                        st.table(pd.DataFrame(recs_data))

else:
    st.info("ğŸ‘‹ Ù…Ø±Ø­Ø¨Ù‹Ø§! Ù„ØªØ¨Ø¯Ø£ØŒ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Excel ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.")
    st.markdown("""
    **ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:**
    * `Ø§Ù„Ø³Ù†Ø©` (Ù…Ø«Ù„Ø§Ù‹: 2022, 2023, 2024)
    * Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù€ 12 (Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬).
    """)
