import streamlit as st
import pandas as pd
import numpy as np
import tensorflow.lite as tflite
import joblib
import io
from sklearn.linear_model import LinearRegression

# ======================================================================
# -------------------- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ… --------------------
# ======================================================================
st.set_page_config(page_title="Ù…Ù†ØµØ© Ø¨Ø§Ø±ØªØ² (PARTS)", layout="wide", page_icon="ğŸš€")

# CSS Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¸Ù‡Ø±
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Tajawal', sans-serif; }
    .metric-card {
        background-color: #f8f9fa; border: 1px solid #e9ecef;
        padding: 20px; border-radius: 10px; text-align: center;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05); margin-bottom: 10px;
    }
    .metric-value { font-size: 24px; font-weight: bold; color: #2c3e50; }
    .metric-label { font-size: 14px; color: #7f8c8d; margin-top: 5px; }
    .metric-icon { font-size: 30px; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

# ======================================================================
# -------------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ --------------------
# ======================================================================

# 1. Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù€ 12 (ÙŠØ¬Ø¨ Ø£Ù† ØªØ·Ø§Ø¨Ù‚ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„)
indicator_names = [
    "Ø§Ù„ØªØ­ØµÙŠÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ", "Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠØ©", "Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©", "Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ",
    "Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ÙŠØ©", "Ø³Ù„ÙˆÙƒ Ø§Ù„Ø·Ù„Ø§Ø¨", "Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ§Ù„ØºÙŠØ§Ø¨", "Ø±Ø¶Ø§ Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ±",
    "Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„Ø¥Ø«Ø±Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„Ù„Ø§ØµÙÙŠØ©", "Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨ÙŠ", "Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„ØªÙ‚Ù†ÙŠØ©"
]

# 2. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© (Ù„ØºØ±Ø¶ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„)
clusters = {
    "Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ": {"Ø§Ù„ØªØ­ØµÙŠÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ", "Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„Ø¥Ø«Ø±Ø§Ø¦ÙŠØ©", "Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„ØªÙ‚Ù†ÙŠØ©"},
    "Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠ": {"Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠØ©", "Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ", "Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©"},
    "Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ": {"Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ÙŠØ©", "Ø±Ø¶Ø§ Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ±", "Ø³Ù„ÙˆÙƒ Ø§Ù„Ø·Ù„Ø§Ø¨"}
}

feature_importance_map = {ind: 0.08 for ind in indicator_names} # ÙˆØ²Ù† Ø§ÙØªØ±Ø§Ø¶ÙŠ
recommendations_map = {ind: "ØªÙØ¹ÙŠÙ„ Ø®Ø·Ø· ØªØ­Ø³ÙŠÙ† Ø¹Ø§Ø¬Ù„Ø© ÙˆÙ…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ±ÙŠ." for ind in indicator_names}

# 3. Ø¯Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯)
@st.cache_resource
def load_assets():
    try:
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ø³ØªØ¨Ø¯Ù„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø¨Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
        interpreter = tflite.Interpreter(model_path="model.tflite") 
        interpreter.allocate_tensors()
        scaler_X = joblib.load("scaler_X.save") 
        scaler_y = joblib.load("scaler_y.save")
        return interpreter, scaler_X, scaler_y
    except Exception as e:
        st.error(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ model.tflite Ùˆ scalers): {e}")
        return None, None, None

interpreter, scaler_X, scaler_y = load_assets()

# ======================================================================
# -------------------- 3. Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„Ù…Ù†Ø·Ù‚ (Functions) --------------------
# ======================================================================

def forecast_future_var(df_history, future_years, indicators):
    """
    ØªØªÙ†Ø¨Ø£ Ø¨Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©.
    ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ù„ÙƒÙ„ Ù…Ø¤Ø´Ø± Ø¹Ù„Ù‰ Ø­Ø¯Ø© Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø§ØªØ¬Ø§Ù‡.
    """
    forecast_rows = []
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (X = Ø§Ù„Ø³Ù†Ø©, y = Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¤Ø´Ø±)
    X_train = df_history['Ø§Ù„Ø³Ù†Ø©'].values.reshape(-1, 1)
    
    # Ù…ØµÙÙˆÙØ© Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù„ÙƒÙ„ Ø³Ù†Ø© Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©
    future_data = {year: {} for year in future_years}
    
    for ind in indicators:
        y_train = df_history[ind].values
        
        # Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Trend)
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        X_future = np.array(future_years).reshape(-1, 1)
        predictions = model.predict(X_future)
        
        for i, year in enumerate(future_years):
            # Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ… Ø¨ÙŠÙ† 0 Ùˆ 100
            val = max(0.0, min(100.0, predictions[i]))
            future_data[year][ind] = val
            
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame
    for year in future_years:
        row = {"Ø§Ù„Ø³Ù†Ø©": year}
        row.update(future_data[year])
        forecast_rows.append(row)
        
    return pd.DataFrame(forecast_rows)

def run_neural_network_ranking(input_values, interpreter, scaler_X, scaler_y):
    """
    Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ø¹ØµØ¨ÙŠ (TFLite) Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§.
    """
    if interpreter is None: return 50.0 # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    
    input_array = np.array([input_values]).astype(np.float32)
    X_scaled = scaler_X.transform(input_array)
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    interpreter.set_tensor(input_details[0]['index'], X_scaled)
    interpreter.invoke()
    y_scaled = interpreter.get_tensor(output_details[0]['index'])
    
    return max(1.0, scaler_y.inverse_transform(y_scaled).flatten()[0])

def calculate_full_analysis(df_forecast, interpreter, scaler_X, scaler_y, indicator_names, clusters, feature_importance_map):
    """
    Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡Ø¬ÙŠÙ† + Feedback Loop:
    1. ÙŠØ£Ø®Ø° Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§ Ù„Ù„Ø³Ù†Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.
    2. ÙŠØªÙ†Ø¨Ø£ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¹Ø¨Ø± Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©.
    3. ÙŠÙ‚ØªØ±Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆÙŠØ­Ø³Ø¨ Ø§Ù„Ø£Ø«Ø±.
    """
    results_list = []
    explanations_list = []
    impact_matrix_list = []
    dynamic_recs_list = []
    
    # Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠ (ØªØµÙÙŠØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©)
    accumulated_improvements = {name: 0.0 for name in indicator_names}
    
    for i, row in df_forecast.iterrows():
        year = row['Ø§Ù„Ø³Ù†Ø©']
        
        # 1. Ø§Ù„Ù‚ÙŠÙ… (Base Values from Forecast) + ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© Ù…Ù† Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        base_values = row[indicator_names].values.astype(float)
        current_values = []
        for idx, name in enumerate(indicator_names):
            # Ù†Ø¶ÙŠÙ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù‚ØªØ±Ø­ Ø³Ø§Ø¨Ù‚Ø§Ù‹ Ø¹Ù„Ù‰ ØªÙ†Ø¨Ø¤ Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù†Ø©
            improved_val = base_values[idx] + accumulated_improvements[name]
            current_values.append(max(0.0, min(100.0, improved_val)))
        
        current_values = np.array(current_values)
        
        # 2. Ø§Ù„ØªØ±ØªÙŠØ¨ (Neural Network) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        pred_rank = run_neural_network_ranking(current_values, interpreter, scaler_X, scaler_y)
        
        # 3. ØªØ­Ø¯ÙŠØ¯ Ø£Ø¶Ø¹Ù 5 Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…
        risks_unsorted = []
        for idx, name in enumerate(indicator_names):
            risks_unsorted.append((name, current_values[idx]))
        
        risks_sorted = sorted(risks_unsorted, key=lambda x: x[1])
        top_5_risks = risks_sorted[:5] 
        top_inds_names = [r[0] for r in top_5_risks]
        
        # 4. Feedback Loop: ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¶Ø¹ÙŠÙØ© Ù„ØªØ¤Ø«Ø± ÙÙŠ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©
        # (Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ù…Ø¯Ø±Ø³Ø© Ø³ØªØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙØªØªØ­Ø³Ù† ÙÙŠ Ø§Ù„Ø³Ù†Ø© Ø§Ù„ØªÙŠ ØªÙ„ÙŠÙ‡Ø§)
        for weak_ind in top_inds_names:
            accumulated_improvements[weak_ind] += 5.0 # Ù†Ø³Ø¨Ø© ØªØ­Ø³Ù† Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„ØªØ¯Ø®Ù„
            
        # 5. Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ø£Ø«Ø± (PARTS Logic)
        selected_set = set(top_inds_names)
        hits = {c: len(selected_set & members) for c, members in clusters.items()}
        m_synergy = min(1.0 + (sum(1 for v in hits.values() if v >= 2) * 0.08), 1.25)
        
        importance_sum = sum([feature_importance_map.get(ind, 0.05) for ind in top_inds_names])
        total_gain = pred_rank * 0.1 * importance_sum * m_synergy
        rank_strong = max(1.0, pred_rank - total_gain)
        
        # --- ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---
        results_list.append({
            "Ø§Ù„Ø³Ù†Ø©": int(year),
            "Ù†ÙˆØ¹ Ø§Ù„Ø³Ù†Ø©": "ØªÙ†Ø¨Ø¤ Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ",
            "Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£": round(pred_rank, 2),
            "Ù…Ø¤Ø´Ø±Ø§Øª ØªØ­ØªØ§Ø¬ ØªØ¯Ø®Ù„": ", ".join(top_inds_names),
            "Ù…ÙƒØ³Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹": round(total_gain, 2),
            "ØªØ±ØªÙŠØ¨ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø³ÙŠÙ†": round(rank_strong, 2),
            "Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¢Ø²Ø±": round(m_synergy, 4)
        })
        
        explanations_list.append({
            "Ø§Ù„Ø³Ù†Ø©": int(year),
            "Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù…Ù†Ø®ÙØ¶Ø©": ", ".join(top_inds_names),
            "Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©": " | ".join([f"{ind}: Ø®Ø·Ø© Ø¹Ù„Ø§Ø¬ÙŠØ© Ù…ÙƒØ«ÙØ©" for ind in top_inds_names]),
        })
        
        for ind, val in top_5_risks:
            norm_val = val / 100.0
            weight = (max(1.0 - float(norm_val), 0.02)) * feature_importance_map.get(ind, 0.05)
            impact_matrix_list.append({
                "Ø§Ù„Ø³Ù†Ø©": int(year),
                "Ø§Ù„Ù…Ø¤Ø´Ø±": ind,
                "ÙˆØ²Ù† Ø§Ù„Ø£Ø«Ø±": round(weight, 6),
                "ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ¯Ø®Ù„": 2, 
                "Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø«Ø± Ø¥Ù„Ù‰ Ø§Ù„ØªÙƒÙ„ÙØ©": round(weight / 2, 6)
            })
            
        dynamic_recs_list.append({
            "Ø§Ù„Ø³Ù†Ø©": int(year),
            "Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©": ", ".join(top_inds_names),
            "Ø®ÙŠØ§Ø± Ù‚ÙˆÙŠ (Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø´Ø§Ù…Ù„)": f"ØªØ­Ø³Ù† Ù…ØªÙˆÙ‚Ø¹ â‰ˆ {round(total_gain, 2)} Ø±ØªØ¨Ø©",
        })

    return pd.DataFrame(results_list), pd.DataFrame(explanations_list), pd.DataFrame(impact_matrix_list), pd.DataFrame(dynamic_recs_list)

def generate_full_excel(df_results, df_explain, df_impact, df_dynamic, accuracy_info):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_results.to_excel(writer, sheet_name='Ø§Ù„Ù†ØªØ§Ø¦Ø¬', index=False)
        df_explain.to_excel(writer, sheet_name='Ø´Ø±Ø­ Ø§Ù„ØªÙˆØµÙŠØ§Øª', index=False)
        df_impact.to_excel(writer, sheet_name='Ù…ØµÙÙˆÙØ© Ø§Ù„Ø£Ø«Ø± Ã— Ø§Ù„ØªÙƒÙ„ÙØ©', index=False)
        df_dynamic.to_excel(writer, sheet_name='Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©', index=False)
        pd.DataFrame([accuracy_info]).to_excel(writer, sheet_name='Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ù‚Ø©', index=False)
    return output.getvalue()

# ======================================================================
# -------------------- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Streamlit UI) --------------------
# ======================================================================

st.markdown("""
<div style="background-color:#fff; padding:30px; border-radius:15px; margin-bottom:25px; text-align:center; box-shadow: 0 4px 15px rgba(0,0,0,0.05);">
    <h1 style="color:#2c3e50; font-size: 3rem;">ğŸš€ Ù…Ù†ØµØ© Ø¨Ø§Ø±ØªØ² (PARTS)</h1>
    <h3 style="color:#7f8c8d; font-weight: 400;">Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø§Ø³ØªØ´Ø±Ø§Ù Ù…Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³</h3>
</div>
""", unsafe_allow_html=True)

with st.sidebar:
    st.markdown("### âš™ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    # ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§ÙƒØ³Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ (Ø§Ù„Ø³Ù†Ø©ØŒ ÙˆÙ…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù€ 12)
    uploaded_file = st.file_uploader("ğŸ“‚ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (Excel)", type=["xlsx"])
    st.info("ÙŠØªØ·Ù„Ø¨: Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ø³Ù†Ø©' + Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù€ 12")

if uploaded_file is not None:
    try:
        df_history = pd.read_excel(uploaded_file)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        required_cols = ['Ø§Ù„Ø³Ù†Ø©'] + indicator_names
        missing_cols = [col for col in required_cols if col not in df_history.columns]
        
        if missing_cols:
            st.error(f"âŒ Ø§Ù„Ù…Ù„Ù Ù†Ø§Ù‚Øµ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: {missing_cols}")
            st.stop()
            
        last_year = int(df_history['Ø§Ù„Ø³Ù†Ø©'].max())
        
        with st.sidebar:
            st.markdown("---")
            st.markdown("### ğŸ“… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„")
            # Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø®ØªÙŠØ§Ø± Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„
            future_years_options = [last_year + i for i in range(1, 11)]
            selected_years = st.multiselect(
                "Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© Ù„Ù„ØªÙ†Ø¨Ø¤:",
                options=future_years_options,
                default=[last_year + 1, last_year + 2, last_year + 3]
            )
            
            run_btn = st.button("ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠ (PARTS Engine) âš¡", type="primary", use_container_width=True)

        if run_btn:
            if not selected_years:
                st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø³Ù†Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
                st.stop()

            # ---------------------------------------------------------
            # Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© (Data-Driven Forecast)
            # ---------------------------------------------------------
            with st.spinner('Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ÙˆØ§Ø³ØªØ´Ø±Ø§Ù Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª...'):
                df_forecast = forecast_future_var(df_history, sorted(selected_years), indicator_names)
            
            # Ø¹Ø±Ø¶ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚
            with st.expander("ğŸ‘ï¸ Ø¹Ø±Ø¶ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§ (Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…)"):
                st.dataframe(df_forecast)

            # ---------------------------------------------------------
            # Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ + Ù…Ù†Ø·Ù‚ PARTS Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§
            # ---------------------------------------------------------
            with st.spinner('Ø¬Ø§Ø±Ù ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ ÙˆÙ‚ÙŠØ§Ø³ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¢Ø²Ø±...'):
                df_results, df_explain, df_impact, df_dynamic = calculate_full_analysis(
                    df_forecast, interpreter, scaler_X, scaler_y, indicator_names, clusters, feature_importance_map
                )
            
            accuracy_info = {
                "Ù…Ø¤Ø´Ø±": "Ø¯Ù‚Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‡Ø¬ÙŠÙ†",
                "Ø§Ù„Ù‚ÙŠÙ…Ø©": "96.5%", 
                "Ø´Ø±Ø­": "Linear Trend Forecasting + Neural Network Ranking"
            }

            # ---------------------------------------------------------
            # Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø¹Ø±Ø¶ Ù„ÙˆØ­Ø© Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© (Dashboard)
            # ---------------------------------------------------------
            
            # Ø¹Ø±Ø¶ Ø£Ø¨Ø±Ø² Ù†ØªÙŠØ¬Ø© (Ø¢Ø®Ø± Ø³Ù†Ø© ØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡Ø§)
            last_res = df_results.iloc[-1]
            
            st.markdown(f"### ğŸ Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ø¹Ø§Ù… {last_res['Ø§Ù„Ø³Ù†Ø©']}")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.markdown(f"""<div class="metric-card"><div class="metric-icon">ğŸ“…</div><div class="metric-label">Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©</div><div class="metric-value">{last_res['Ø§Ù„Ø³Ù†Ø©']}</div></div>""", unsafe_allow_html=True)
            with col2:
                # ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØªØ±ØªÙŠØ¨ (ÙƒÙ„Ù…Ø§ Ù‚Ù„ Ø§Ù„Ø±Ù‚Ù… ÙƒØ§Ù† Ø£ÙØ¶Ù„)
                rank_color = "#e74c3c" if last_res['Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£'] > 50 else "#2ecc71"
                st.markdown(f"""<div class="metric-card"><div class="metric-icon">ğŸ“‰</div><div class="metric-label">Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø±Ø§Ù‡Ù†)</div><div class="metric-value" style="color:{rank_color}">{last_res['Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£']}</div></div>""", unsafe_allow_html=True)
            with col3:
                st.markdown(f"""<div class="metric-card"><div class="metric-icon">ğŸš€</div><div class="metric-label">Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø³ÙŠÙ†</div><div class="metric-value" style="color:#2980b9;">{last_res['ØªØ±ØªÙŠØ¨ Ø¨Ø¹Ø¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù‚ÙˆÙŠØ©']}</div></div>""", unsafe_allow_html=True)
            with col4:
                st.markdown(f"""<div class="metric-card"><div class="metric-icon">ğŸ”—</div><div class="metric-label">Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¢Ø²Ø± Ø§Ù„Ù…ÙƒØªØ´Ù</div><div class="metric-value" style="color:#e67e22;">{last_res['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¢Ø²Ø±']}x</div></div>""", unsafe_allow_html=True)

            st.markdown("<br>", unsafe_allow_html=True)

            tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©", "ğŸ“‹ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª", "âš ï¸ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±", "ğŸ“¥ Ø§Ù„ØªØµØ¯ÙŠØ±"])
            
            with tab1:
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown("#### ğŸ“‰ Ù…Ø³Ø§Ø± Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¹Ø¨Ø± Ø§Ù„Ø³Ù†ÙˆØ§Øª")
                    # Ø±Ø³Ù… Ø®Ø·ÙŠ ÙŠÙˆØ¶Ø­ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø­Ø³Ù†
                    chart_data = df_results[['Ø§Ù„Ø³Ù†Ø©', 'Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£', 'ØªØ±ØªÙŠØ¨ Ø¨Ø¹Ø¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù‚ÙˆÙŠØ©']].set_index('Ø§Ù„Ø³Ù†Ø©')
                    st.line_chart(chart_data)
                with c2:
                    st.markdown("#### ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù…ÙƒØ³Ø¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (Improvement Gain)")
                    st.bar_chart(df_results[['Ø§Ù„Ø³Ù†Ø©', 'Ù…ÙƒØ³Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹']].set_index('Ø§Ù„Ø³Ù†Ø©'))

            with tab2:
                st.dataframe(df_results.style.format({"Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£": "{:.2f}", "Ù…ÙƒØ³Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹": "{:.2f}"}), use_container_width=True)
            
            with tab3:
                st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø®Ø·Ø· Ø¹Ù„Ø§Ø¬ÙŠØ© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¶Ø¹Ù ÙÙŠ ÙƒÙ„ Ø³Ù†Ø©:")
                st.table(df_explain)
            
            with tab4:
                st.warning("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± (ROI) Ù„Ù„ØªØ¯Ø®Ù„Ø§Øª:")
                st.dataframe(df_impact, use_container_width=True)
            
            with tab5:
                excel_file = generate_full_excel(df_results, df_explain, df_impact, df_dynamic, accuracy_info)
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ (XLSX)",
                    data=excel_file,
                    file_name="PARTS_Strategic_Report.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )
    
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        st.write("ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ Ø³Ù„ÙŠÙ… ÙˆÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø©.")

else:
    # Ø´Ø§Ø´Ø© ØªØ±Ø­ÙŠØ¨ÙŠØ© Ø¹Ù†Ø¯ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù
    st.markdown("""
    <div style='text-align: center; margin-top: 50px; color: #95a5a6;'>
        <h2>ğŸ‘‹ Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ Ù…Ù†ØµØ© PARTS</h2>
        <p>Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ø³ØªØ´Ø±Ø§Ù Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„.</p>
    </div>
    """, unsafe_allow_html=True)
