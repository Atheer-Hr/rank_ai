import streamlit as st
import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
from tensorflow.lite import Interpreter
import os
from typing import Tuple, Dict, Any, List

# ======================================================================
# -------------------- 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (TFLITE) --------------------
# ======================================================================

@st.cache_resource
def load_assets_lite() -> Tuple[Any, Any, Any, List, Dict, Dict, Dict, Dict]:
    
    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„Ø«Ø§Ø¨ØªØ© (Static Dictionaries)
    recommendations_map = {
        "Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù„Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ø´Ø±ÙŠ": "ØªØ·ÙˆÙŠØ± Ø¨Ø±Ø§Ù…Ø¬ ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ù…Ø³ØªÙ…Ø±Ø© Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙØ±Ø¯ÙŠ.",
        "Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬": "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù…Ù†Ø§Ù‡Ø¬ ÙˆØªØ­Ø¯ÙŠØ«Ù‡Ø§ Ù„ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø±Ù† 21.",
        "Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ": "Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù‡Ù†ÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ù…Ø¹ Ø­ÙˆØ§ÙØ² Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ø§Ø².",
        "ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø´Ø®ØµÙŠØ©": "Ø¥Ø·Ù„Ø§Ù‚ Ø¨Ø±Ø§Ù…Ø¬ Ø¥Ø±Ø´Ø§Ø¯ Ù†ÙØ³ÙŠ ÙˆØ§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ù‚ÙŠØ§Ø¯Ø© Ù„Ø¯Ù‰ Ø§Ù„Ø·Ù„Ø§Ø¨.",
        "Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªØ±Ø¨ÙˆÙŠ": "ØªØ·ÙˆÙŠØ± Ø£Ø¯ÙˆØ§Øª ØªÙ‚ÙŠÙŠÙ… Ù…Ø¹ÙŠØ§Ø±ÙŠØ© Ø±Ù‚Ù…ÙŠØ© Ù„Ù‚ÙŠØ§Ø³ Ù†ÙˆØ§ØªØ¬ Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø¯Ù‚Ø©.",
        "Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø§Øµ": "ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø´Ø±Ø§ÙƒØ§Øª Ù…Ø¹ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ù„Ø¯Ø¹Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù…Ù„ÙŠ ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„ØªÙ‚Ù†ÙŠØ©.",
        "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø³Ø±Ø©": "ØªÙØ¹ÙŠÙ„ Ù…Ø¬Ø§Ù„Ø³ Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ¥Ø´Ø±Ø§ÙƒÙ‡Ù… ÙÙŠ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ.",
        "Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ù…Ø¨Ø§Ù†ÙŠ": "ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© ÙˆØªÙˆÙÙŠØ± Ø¨ÙŠØ¦Ø© ØµÙÙŠØ© Ø¬Ø§Ø°Ø¨Ø© ÙˆØ¢Ù…Ù†Ø©.",
        "Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³": "ØªØ¹Ù…ÙŠÙ… Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ù…Ù†ØµØ§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø±Ù‚Ù…ÙŠØ©.",
        "Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ": "Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs) Ù„Ù…ØªØ§Ø¨Ø¹Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ.",
        "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ³": "ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªØ¹Ù„Ù… Ù†Ø´Ø· ÙˆØªØ¯Ø±ÙŠØ³ ØªÙØ±ÙŠØ¯ÙŠØ© ØªØ±Ø§Ø¹ÙŠ Ø§Ù„ÙØ±ÙˆÙ‚ Ø§Ù„ÙØ±Ø¯ÙŠØ©.",
        "Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©": "Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø¹ÙŠØ§Ø±ÙŠØ© ÙˆØ·Ù†ÙŠØ© Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ ÙˆØ§Ù„Ù…Ù†Ø§Ø·Ù‚."
    }
    
    execution_plan_map = {
        "Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù„Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ø´Ø±ÙŠ": "ØªÙˆØ²ÙŠØ¹ Ø¨Ø±Ø§Ù…Ø¬ ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø­Ø³Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ù†ÙˆÙŠ.",
        "Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬": "ØªØ´ÙƒÙŠÙ„ Ù„Ø¬Ø§Ù† Ù…Ø±Ø§Ø¬Ø¹Ø© Ù„Ù„Ù…Ù†Ø§Ù‡Ø¬ ÙˆØ±Ø¨Ø· Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©.",
        "Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ": "ØªØµÙ…ÙŠÙ… Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù‡Ù†ÙŠØ© ÙØ±Ø¯ÙŠØ© Ù…Ø¹ Ù…ØªØ§Ø¨Ø¹Ø© ÙØµÙ„ÙŠØ© ÙˆØªÙ‚ÙŠÙŠÙ… ØªØ·Ø¨ÙŠÙ‚ÙŠ.",
        "ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø´Ø®ØµÙŠØ©": "ØªÙ†ÙÙŠØ° Ø£Ù†Ø´Ø·Ø© ØµÙÙŠØ© ÙˆÙ„Ø§ØµÙÙŠØ© ØªØ¹Ø²Ø² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙˆØ§Ù„Ø§Ù†Ø¶Ø¨Ø§Ø· Ø§Ù„Ø°Ø§ØªÙŠ.",
        "Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªØ±Ø¨ÙˆÙŠ": "Ø¥Ø¹Ø§Ø¯Ø© ØªØµÙ…ÙŠÙ… Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙ‚ÙˆÙŠÙ… ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ.",
        "Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø§Øµ": "ØªÙˆÙ‚ÙŠØ¹ Ø§ØªÙØ§Ù‚ÙŠØ§Øª ØªØ¹Ø§ÙˆÙ† Ù…Ø¹ Ø´Ø±ÙƒØ§Øª Ù…Ø­Ù„ÙŠØ© Ù„Ø¯Ø¹Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ù…Ø±Ø§ÙÙ‚.",
        "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø³Ø±Ø©": "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØµØ© ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡.",
        "Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ù…Ø¨Ø§Ù†ÙŠ": "ØªØ­Ø¯ÙŠØ¯ Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„ØµÙŠØ§Ù†Ø© ÙˆØ§Ù„ØªØ¬Ù‡ÙŠØ² Ø­Ø³Ø¨ ÙƒØ«Ø§ÙØ© Ø§Ù„Ø·Ù„Ø§Ø¨.",
        "Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³": "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© ÙˆØ±Ø¨Ø·Ù‡Ø§ Ø¨Ù…Ù†ØµØ§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ø¹Ù„ÙŠÙ‡Ø§.",
        "Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ": "ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø§Ù… Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ Ø´Ù‡Ø±ÙŠ ÙˆØ±Ø¨Ø·Ù‡ Ø¨Ø§Ù„ØªØ­ÙÙŠØ² Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠ.",
        "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ³": "ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø· ÙˆØ§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªÙƒÙˆÙŠÙ†ÙŠ.",
        "Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©": "ØªØµÙ…ÙŠÙ… Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ·Ù†ÙŠØ© Ù…ÙˆØ­Ø¯Ø© ÙˆØ±Ø¨Ø· Ù†ØªØ§Ø¦Ø¬Ù‡Ø§ Ø¨Ø®Ø·Ø· Ø§Ù„ØªØ­Ø³ÙŠÙ†."
    }
    
    clusters = {
        "ØªØ¹Ù„ÙŠÙ…": {"Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ³","Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬","Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ"},
        "ØªÙ‚ÙŠÙŠÙ…": {"Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„ØªØ±Ø¨ÙˆÙŠ","Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©","Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ"},
        "Ø£Ø³Ø±Ø© ÙˆÙ…Ø¬ØªÙ…Ø¹": {"Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø³Ø±Ø©","Ø§Ù„Ø´Ø±Ø§ÙƒØ© Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø§Øµ","ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø´Ø®ØµÙŠØ©"},
        "Ø¨ÙŠØ¦Ø© ÙˆØªØ¬Ù‡ÙŠØ²": {"Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ù…Ø¨Ø§Ù†ÙŠ","Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³"}
    }

    default_return = None, None, None, [], None, None, None, None

    try:
        # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ranking Model)
        if not os.path.exists('ranking_model_lite.tflite'):
             st.error("âŒ Ø®Ø·Ø£: Ù…Ù„Ù 'ranking_model_lite.tflite' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡ Ø¨Ø¬Ø§Ù†Ø¨ Ù…Ù„Ù Ø§Ù„ÙƒÙˆØ¯.")
             return default_return
        
        interpreter = Interpreter(model_path='ranking_model_lite.tflite')
        interpreter.allocate_tensors()

        # 2. ØªØ­Ù…ÙŠÙ„ Scalers
        if not os.path.exists('scaler_X_lite.pkl') or not os.path.exists('scaler_y_lite.pkl'):
             st.error("âŒ Ø®Ø·Ø£: Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ Scaler (.pkl) Ù…ÙÙ‚ÙˆØ¯Ø©.")
             return default_return

        scaler_X = joblib.load('scaler_X_lite.pkl')
        scaler_y = joblib.load('scaler_y_lite.pkl')
        
        # 3. ØªØ­Ù…ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        if not os.path.exists('indicator_names_lite.txt'):
             st.error("âŒ Ø®Ø·Ø£: Ù…Ù„Ù Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ 'indicator_names_lite.txt' Ù…ÙÙ‚ÙˆØ¯.")
             return default_return

        with open('indicator_names_lite.txt', 'r', encoding='utf-8') as f:
            indicator_names = [line.strip() for line in f]
            
        # 4. ØªØ­Ù…ÙŠÙ„ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (Ù…Ø¹ Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù†Ø§Ù‚ØµØ§Ù‹)
        if os.path.exists('feature_importance_map.pkl'):
            feature_importance_map = joblib.load('feature_importance_map.pkl')
        else:
            # âš ï¸ Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ø£Ù† Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
            st.warning("âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ù…Ù„Ù 'feature_importance_map.pkl' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø£Ù‡Ù…ÙŠØ©.")
            feature_importance_map = {name: 1.0 for name in indicator_names}

        return interpreter, scaler_X, scaler_y, indicator_names, recommendations_map, execution_plan_map, clusters, feature_importance_map
    
    except Exception as e:
        st.error(f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª: {e}")
        return default_return

# ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù…ÙŠÙ„
interpreter, scaler_X, scaler_y, indicator_names, recommendations_map, execution_plan_map, clusters, feature_importance_map = load_assets_lite()

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¢Ø²Ø±
def synergy_multiplier(selected_inds, clusters):
    selected = set(selected_inds)
    hits = {c: len(selected & members) for c, members in clusters.items()}
    same_cluster_boost = sum(1 for _, v in hits.items() if v >= 2) * 0.08
    multi_cluster_boost = sum(1 for _, v in hits.items() if v >= 1) * 0.03
    m = 1.0 + same_cluster_boost + multi_cluster_boost
    return min(m, 1.25)


# ======================================================================
# -------------------- 2. ÙˆØ¸ÙŠÙØ© Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ (TFLite) --------------------
# ======================================================================

def run_prediction_and_analysis(input_values, interpreter, scaler_X, scaler_y, indicator_names, clusters, feature_importance_map):
    
    if interpreter is None:
        return None, None, None, None, None, None, None, None

    # 1. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    input_array = np.array([input_values]).astype(np.float32)
    
    # 2. Ø§Ù„ØªØ·Ø¨ÙŠØ¹
    try:
        X_scaled = scaler_X.transform(input_array)
    except ValueError as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return None, None, None, None, None, None, None, None

    # 3. Ø§Ù„ØªÙ†Ø¨Ø¤
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    interpreter.set_tensor(input_details[0]['index'], X_scaled.astype(np.float32))
    interpreter.invoke()
    y_scaled = interpreter.get_tensor(output_details[0]['index'])

    y_pred_orig = scaler_y.inverse_transform(y_scaled).flatten()[0]
    
    # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
    risks_sorted = sorted([(indicator_names[j], X_scaled[0, j]) for j in range(len(indicator_names))], key=lambda x: x[1])
    top_inds = [r[0] for r in risks_sorted[:5]]

    # 5. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙƒØ§Ø³Ø¨
    m_synergy = synergy_multiplier(top_inds, clusters)
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… .get Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
    total_gain = y_pred_orig * 0.1 * sum([feature_importance_map.get(ind, 1.0) for ind in top_inds]) * m_synergy
    
    rank_strong = max(1.0, y_pred_orig - total_gain)
    rank_partial = max(1.0, y_pred_orig - total_gain * 0.6)
    rank_weak = max(1.0, y_pred_orig - total_gain * 0.3)
    
    # 6. Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
    impact_cost_rows = []
    for ind, norm_val in risks_sorted:
        importance = feature_importance_map.get(ind, 1.0)
        base_component = max(1.0 - float(norm_val), 0.02)
        weight = base_component * importance
        impact_cost_rows.append({
            "Ø§Ù„Ù…Ø¤Ø´Ø±": ind,
            "Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø«Ø± Ø¥Ù„Ù‰ Ø§Ù„ØªÙƒÙ„ÙØ©": weight / 2
        })
    df_impact = pd.DataFrame(impact_cost_rows)
    df_impact["ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"] = df_impact["Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø«Ø± Ø¥Ù„Ù‰ Ø§Ù„ØªÙƒÙ„ÙØ©"].rank(ascending=False, method="dense").astype(int)
    
    if df_impact.empty:
        priority_1_indicator = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    else:
        priority_1_indicator = df_impact[df_impact["ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"] == 1]['Ø§Ù„Ù…Ø¤Ø´Ø±'].iloc[0]
    
    return y_pred_orig, rank_strong, rank_partial, rank_weak, total_gain, m_synergy, top_inds, priority_1_indicator


# ======================================================================
# -------------------- 3. ÙˆØ§Ø¬Ù‡Ø© Streamlit --------------------
# ======================================================================

if interpreter is not None and indicator_names:
    st.set_page_config(layout="wide", page_title="Ù…Ù†ØµØ© Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ")
    
    st.markdown("""
        <style>
            .arabic-font { font-family: 'Tahoma', sans-serif; direction: rtl; text-align: right; }
            [data-testid="stSidebar"] { direction: rtl; text-align: right; }
            .big-font { font-size: 30px !important; font-weight: bold; color: #004d99; }
            div[data-testid="stMetricValue"] { direction: rtl; }
            p, h1, h2, h3 { text-align: right; }
        </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="arabic-font big-font">ğŸš€ Ù…Ù†ØµØ© Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ (AI Prescriptive Agent)</p>', unsafe_allow_html=True)
    st.markdown('<p class="arabic-font">Ø£Ø¯Ø®Ù„ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ø¹Ø§Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ (2025-2030) ÙˆØ§Ø³ØªØ¹Ø±Ø¶ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© ÙˆØ£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„ØªØ¯Ø®Ù„.</p>', unsafe_allow_html=True)

    # --- Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ---
    st.sidebar.markdown('### âš™ï¸ Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª')
    input_cols = st.sidebar.columns(2)
    input_values = []
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙŠØ·Ø§Ø¨Ù‚ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
    for i, ind_name in enumerate(indicator_names):
        col = input_cols[i % 2]
        with col:
            # Ø¬Ø¹Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨ Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„ØªØ¬Ø±Ø¨Ø©
            val = st.slider(f"{ind_name}", 0.0, 100.0, 50.0, key=f"input_{i}")
            input_values.append(val)

    # --- Ø§Ù„Ø²Ø± ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ ---
    if st.sidebar.button('ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª'):
        
        results = run_prediction_and_analysis(
            input_values, interpreter, scaler_X, scaler_y, indicator_names, clusters, feature_importance_map
        )
        
        if results[0] is not None:
            y_pred, r_strong, r_partial, r_weak, gain, synergy, top_inds, p1_ind = results
            
            st.header("ğŸ¥‡ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            st.markdown("---")
            
            c1, c2, c3 = st.columns(3)
            c1.metric("Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ØªÙ†Ø¨Ø£", f"{y_pred:.2f} Ø±ØªØ¨Ø©")
            c2.metric("Ø§Ù„Ù…ÙƒØ³Ø¨ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹", f"+{gain:.2f}", f"ØªØ¢Ø²Ø±: {synergy:.2f}")
            c3.metric("Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù‚ØµÙˆÙ‰", p1_ind)
            
            st.subheader("Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©")
            df_chart = pd.DataFrame({
                'Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ': ['Ø§Ù„Ø­Ø§Ù„ÙŠ', 'ØªØ¯Ø®Ù„ Ø¶Ø¹ÙŠÙ', 'ØªØ¯Ø®Ù„ Ø¬Ø²Ø¦ÙŠ', 'ØªØ¯Ø®Ù„ Ù‚ÙˆÙŠ'],
                'Ø§Ù„ØªØ±ØªÙŠØ¨': [y_pred, r_weak, r_partial, r_strong]
            })
            st.bar_chart(df_chart.set_index('Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ'))

            st.header("ğŸ“ Ø§Ù„ØªÙˆØµÙŠØ§Øª")
            recs = []
            for ind in top_inds:
                recs.append({
                    "Ø§Ù„Ù…Ø¤Ø´Ø±": ind,
                    "Ø§Ù„ØªÙˆØµÙŠØ©": recommendations_map.get(ind, '-'),
                    "Ø§Ù„Ø®Ø·Ø©": execution_plan_map.get(ind, '-')
                })
            st.table(pd.DataFrame(recs))

elif interpreter is None:
    st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯.")
